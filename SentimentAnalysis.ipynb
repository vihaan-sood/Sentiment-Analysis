{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project compares the performance of theory-driven and data-driven methods for classification of reviews into three classes - positive, negative and neutral. In particular between Naive Bayes using lemmatisation, bigrams and trigrams AND fine tuned BERT model (encoder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the drug-review dataset found at https://www.kaggle.com/datasets/mohamedabdelwahabali/drugreview?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy pandas nltk cupy scikit-learn spacy transformers datasets torch\n",
    "#python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 2)\n",
      "(1000, 2)\n",
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_raw = pd.read_csv(\"archive/drug_review_train.csv\", usecols=[\"review\", \"rating\"]).to_numpy()\n",
    "test_raw = pd.read_csv(\"archive/drug_review_test.csv\", usecols=[\"review\", \"rating\"]).to_numpy()\n",
    "val_raw = pd.read_csv(\"archive/drug_review_validation.csv\", usecols=[\"review\", \"rating\"]).to_numpy()\n",
    "\n",
    "np.random.seed(50)\n",
    "\n",
    "np.random.shuffle(train_raw)\n",
    "np.random.shuffle(test_raw)\n",
    "np.random.shuffle(val_raw)\n",
    "\n",
    "train_raw = train_raw[:8000]       #Using a 80:10:10 split (a subset of the data)\n",
    "test_raw = test_raw[:1000]  \n",
    "val_raw = val_raw[:1000]  \n",
    "\n",
    "print(train_raw.shape)\n",
    "print(test_raw.shape)\n",
    "print(val_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"reporting in. after 5 weeks of stopping the anastrazole, my joint pain was pretty much gone and i was ecstatic! due to serious family illness, i had to postpone my follow up visit with my oncologist. fearing that i had been off the med long enough, i started taking it again. that was a week ago. the joint pain came back today with a vengeance  - aching knees, aching back, shortness of breath, barely able to walk. i cannot take this med anymore and it worries me as the alternatives (tamoxifen) are not as effective. see my doc in five days. will post again. my heart goes out to all the women posting on this forum.\"\n",
      "[0 1 1 -1 -1 1 1 0 1 -1 1 -1 1 1 1 1 -1 0 1 -1 -1 1 0 -1 0 -1 1 -1 -1 0 1\n",
      " 1 0 1 1 -1 -1 1 1 1 0 1 1 1 0 -1 1 1 1 1 1 1 1 1 1 1 0 -1 1 1 1 -1 1 1 1\n",
      " 1 -1 1 -1 1 1 1 0 -1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 -1 0 -1 -1 -1 1 -1 1 1 1\n",
      " 1 -1]\n"
     ]
    }
   ],
   "source": [
    "def seperate_ratings_and_text(data):\n",
    "    text = data[:,0]\n",
    "    ratings = data[:,1]\n",
    "    return text,ratings\n",
    "\n",
    "\n",
    "train_raw_text,train_raw_ratings = seperate_ratings_and_text(train_raw)\n",
    "test_raw_text,test_raw_ratings = seperate_ratings_and_text(test_raw)\n",
    "val_raw_text,val_raw_ratings = seperate_ratings_and_text(val_raw)\n",
    "\n",
    "\n",
    "def convert_rating_to_sentiment(rating_list):           # 1 -> pos, 0 -> neut,-1 -> neg sentiment\n",
    "\n",
    "    for i in range(len(rating_list)):\n",
    "        rating = int(rating_list[i] )\n",
    "        if rating >= 7:\n",
    "            rating_list[i] = 1\n",
    "        elif rating <= 4:\n",
    "            rating_list[i] = -1\n",
    "        else:\n",
    "            rating_list[i] = 0\n",
    "\n",
    "    return rating_list\n",
    "\n",
    "convert_rating_to_sentiment(train_raw_ratings)\n",
    "convert_rating_to_sentiment(test_raw_ratings)\n",
    "convert_rating_to_sentiment(val_raw_ratings)\n",
    "\n",
    "print(train_raw_text[0])\n",
    "print(train_raw_ratings[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reporting in after 5 weeks of stopping the anastrazole my joint pain was pretty much gone and i was ecstatic due to serious family illness i had to postpone my follow up visit with my oncologist fearing that i had been off the med long enough i started taking it again that was a week ago the joint pain came back today with a vengeance aching knees aching back shortness of breath barely able to walk i cannot take this med anymore and it worries me as the alternatives tamoxifen are not as effective see my doc in five days will post again my heart goes out to all the women posting on this forum\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_review(review):                                       #keeping only alphanumeric words\n",
    "    review = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", review)\n",
    "    review = re.sub(r\"\\s+\", \" \", review) \n",
    "    review = review.lower()\n",
    "    return review\n",
    "\n",
    "def clean_text(text_list):\n",
    "    cleaned_sentences = [clean_review(sentence) for sentence in text_list]\n",
    "    return np.array(cleaned_sentences)\n",
    "\n",
    "\n",
    "\n",
    "train_cleaned = clean_text(train_raw_text)\n",
    "test_cleaned = clean_text(test_raw_text)\n",
    "val_cleaned = clean_text(val_raw_text)\n",
    "\n",
    "print(train_cleaned[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lemmatizer needs the PoS of the word to properly lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopWords = set(stopwords.words(\"english\"))\n",
    "\n",
    "#PoS mapping\n",
    "pos_mapping = {\n",
    "    \"NOUN\": \"n\",\n",
    "    \"PROPN\": \"n\",\n",
    "    \"VERB\": \"v\",\n",
    "    \"AUX\": \"v\",\n",
    "    \"ADJ\": \"a\",\n",
    "    \"ADV\": \"r\",\n",
    "}\n",
    "\n",
    "#cache dictionary for lemmatized words with PoS\n",
    "lemmatized_cache = {}\n",
    "\n",
    "def lemmatize_word(word, pos):\n",
    "\n",
    "    key = (word, pos)  #use word and PoS as the key\n",
    "    if key in lemmatized_cache:\n",
    "        return lemmatized_cache[key]\n",
    "\n",
    "    #compute lemmatized form and cache it\n",
    "    lemmatized_word = lemmatizer.lemmatize(word, pos_mapping.get(pos, \"n\"))\n",
    "    lemmatized_cache[key] = lemmatized_word\n",
    "    return lemmatized_word\n",
    "\n",
    "def better_lemmatizer(single_sentence):\n",
    "\n",
    "    #clean the sentence (assuming clean_review is defined)\n",
    "    single_sentence = clean_review(single_sentence)\n",
    "\n",
    "    #get PoS tags for the sentence\n",
    "    text_PoS = nlp(single_sentence)\n",
    "\n",
    "    #remove stopwords, lemmatize\n",
    "    lemmatized_list = [\n",
    "        lemmatize_word(token.text.lower(), token.pos_)\n",
    "        for token in text_PoS\n",
    "        if token.text.lower() not in stopWords\n",
    "    ]\n",
    "\n",
    "    return lemmatized_list\n",
    "\n",
    "def lemmatize(data):\n",
    "\n",
    "    res = []\n",
    "    for i in range(len(data)):\n",
    "        res.append(better_lemmatizer(data[i]))\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# Example usage\n",
    "train_lem = lemmatize(train_cleaned)  \n",
    "test_lem = lemmatize(test_cleaned)   \n",
    "val_lem = lemmatize(val_cleaned)    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['report 5 week stop anastrazole joint pain pretty much go ecstatic due serious family illness postpone follow visit oncologist fearing med long enough start take week ago joint pain come back today vengeance ache knee ache back shortness breath barely able walk take med anymore worry alternative tamoxifen effective see doc five day post heart go woman post forum', 'imagine awe use sleep even camp heat storm tent 20 maybe exhausted mountain trek 30 major issue except occasional job stress ex loud snore change 40 within 5 month mom die get divorce stab street robbery sleep sometimes almost impossible read site probably look answer love one prescribe many thing drs repeatedly tell traz best nonaddictive allow stage sleep cycle work great albeit funky dream nextday grogginess never leave many month quit absolutely withdrawal']\n",
      "8000\n",
      "['three week ago begin around 20 hot flash per day go night sweat 4 time per night 5 day ago doctor put pristiq father recently pass away several personal thing happen nt start period month either say would take care night sweat hot flash depression grief anxiety pill 5 day lose four lb go pk cigarette per day four cigarette get night sweat twice night go 21 hot flash per day 4 far good feel little tired agitation confusion cry emptiness feel like slowly get back far thankful pristiq', 'lupron shoot almost 2 year first six month hard wake tired icky feel puke lose appetite lose lot weight make insomnia bad urge pee bad especially night nausea settle appetite come back side effect easy cope top side effect implanon nt bleed pain get 3 month shooting pain come back bleeding get put back decide take break crampy start spot obgyn say nt pain like shall wait see since lupron work medicaid wo nt let lap see stage endometriosis']\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "train_lem_str = [\" \".join(row) for row in train_lem]\n",
    "test_lem_str = [\" \".join(row) for row in test_lem]\n",
    "val_lem_str = [\" \".join(row) for row in val_lem]\n",
    "\n",
    "print(train_lem_str[0:2])\n",
    "print(len(train_lem_str))\n",
    "print(test_lem_str[0:2])\n",
    "print(len(test_lem_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using skikit-learn, we make unigrams, bigrams and trigrams of the lemmatized text and pass these as features for Naive Bayes. Here noun phrases and other methods such as wikification could also have been used to boost features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3),max_features=60000)\n",
    "\n",
    "train_count = vectorizer.fit_transform(train_lem_str)\n",
    "test_count = vectorizer.transform(test_lem_str)\n",
    "\n",
    "val_count = vectorizer.transform(val_lem_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0025' '005' '005 mg' ... 'zyprexa' 'zyprexa 75' 'zyrtec']\n",
      "(8000, 60000)\n",
      "(1000, 60000)\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 82 stored elements and shape (1, 60000)>\n",
      "  Coords\tValues\n",
      "  (0, 44867)\t0.10140881982506662\n",
      "  (0, 57957)\t0.07334083521124661\n",
      "  (0, 51319)\t0.047481783295737705\n",
      "  (0, 3872)\t0.14584100101572434\n",
      "  (0, 25320)\t0.17532767623764836\n",
      "  (0, 38600)\t0.08738052674078056\n",
      "  (0, 42224)\t0.06733613946867814\n",
      "  (0, 33877)\t0.049159079163035115\n",
      "  (0, 19293)\t0.06758674857020708\n",
      "  (0, 11790)\t0.1319390090807676\n",
      "  (0, 11593)\t0.06253622579605236\n",
      "  (0, 46773)\t0.08985474692447291\n",
      "  (0, 14625)\t0.08266992103340727\n",
      "  (0, 23748)\t0.10649766934711857\n",
      "  (0, 41578)\t0.13745965835717122\n",
      "  (0, 16962)\t0.078754679761918\n",
      "  (0, 57581)\t0.09347094858679746\n",
      "  (0, 37692)\t0.13446822768017172\n",
      "  (0, 30436)\t0.12453116282612124\n",
      "  (0, 28462)\t0.058056630669080664\n",
      "  (0, 12493)\t0.0710087844988108\n",
      "  (0, 50090)\t0.03624585348647605\n",
      "  (0, 53063)\t0.05173597986660481\n",
      "  (0, 2596)\t0.052039190917262654\n",
      "  (0, 8614)\t0.05408680236059698\n",
      "  :\t:\n",
      "  (0, 50549)\t0.06441340719082386\n",
      "  (0, 54437)\t0.09003604648951405\n",
      "  (0, 57978)\t0.07912548523155684\n",
      "  (0, 38675)\t0.1183753269395663\n",
      "  (0, 8619)\t0.07893903500136827\n",
      "  (0, 6024)\t0.14584100101572434\n",
      "  (0, 1820)\t0.14584100101572434\n",
      "  (0, 47359)\t0.11105289643256584\n",
      "  (0, 6585)\t0.14112087361067144\n",
      "  (0, 1670)\t0.11391358981471532\n",
      "  (0, 57722)\t0.13446822768017172\n",
      "  (0, 53791)\t0.09463508519963762\n",
      "  (0, 46377)\t0.13446822768017172\n",
      "  (0, 16740)\t0.10919346240966246\n",
      "  (0, 10062)\t0.13745965835717122\n",
      "  (0, 21750)\t0.1319390090807676\n",
      "  (0, 41546)\t0.14584100101572434\n",
      "  (0, 38950)\t0.14584100101572434\n",
      "  (0, 42265)\t0.13745965835717122\n",
      "  (0, 12544)\t0.14584100101572434\n",
      "  (0, 50617)\t0.1319390090807676\n",
      "  (0, 54439)\t0.12309545434461916\n",
      "  (0, 38676)\t0.13446822768017172\n",
      "  (0, 6586)\t0.14584100101572434\n",
      "  (0, 1671)\t0.14584100101572434\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())\n",
    "print(train_count.shape)\n",
    "print(test_count.shape)\n",
    "print(train_count[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Evaluation:\n",
      "Accuracy: 0.68\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.00      0.01       232\n",
      "           0       0.00      0.00      0.00        89\n",
      "           1       0.68      1.00      0.81       679\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.56      0.33      0.27      1000\n",
      "weighted avg       0.69      0.68      0.55      1000\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.681\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       233\n",
      "           0       0.00      0.00      0.00        86\n",
      "           1       0.68      1.00      0.81       681\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.23      0.33      0.27      1000\n",
      "weighted avg       0.46      0.68      0.55      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vihaa\\Documents\\GitHub (not onedrive)\\Sentiment-Analysis\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vihaa\\Documents\\GitHub (not onedrive)\\Sentiment-Analysis\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vihaa\\Documents\\GitHub (not onedrive)\\Sentiment-Analysis\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vihaa\\Documents\\GitHub (not onedrive)\\Sentiment-Analysis\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vihaa\\Documents\\GitHub (not onedrive)\\Sentiment-Analysis\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vihaa\\Documents\\GitHub (not onedrive)\\Sentiment-Analysis\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(train_count, train_raw_ratings.astype(int))\n",
    "\n",
    "val_predictions = model.predict(val_count)\n",
    "\n",
    "print(\"Validation Set Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(val_raw_ratings.astype(int), val_predictions))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(val_raw_ratings.astype(int), val_predictions))\n",
    "\n",
    "test_predictions = model.predict(test_count)\n",
    "\n",
    "print(\"Test Set Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(test_raw_ratings.astype(int), test_predictions))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_raw_ratings.astype(int), test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now we use BERT to classify the reviews. This is different to the previous approach as it is not feature based and hence there is no need to find any PoS/Unigrams/Bigrams etc. The model will be trained on the data and the weights will contain all the necessary information regarding the words. \n",
    "\n",
    "\n",
    " Using CUDA for GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ.get(\"CUDA_VISIBLE_DEVICES\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.7.0.dev20250117+cu126\n",
      "CUDA Available: True\n",
      "CUDA Version: 12.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA Version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_raw_text = np.array(train_raw_text).reshape(-1, 1)\n",
    "train_raw_ratings = np.array(train_raw_ratings+1).reshape(-1, 1)        #incrementing the rating value by 1 for the model, has no effect on classification\n",
    "                                                                        # 2 -> pos, 1 -> neut, 0 -> neg sentiment\n",
    "test_raw_text = np.array(test_raw_text).reshape(-1, 1)\n",
    "test_raw_ratings = np.array(test_raw_ratings+1).reshape(-1, 1)\n",
    "\n",
    "val_raw_text = np.array(val_raw_text).reshape(-1, 1)\n",
    "val_raw_ratings = np.array(val_raw_ratings+1).reshape(-1, 1)\n",
    "\n",
    "train_concat_raw = np.hstack((train_raw_text, train_raw_ratings))\n",
    "test_concat_raw = np.hstack((test_raw_text, test_raw_ratings))\n",
    "val_concat_raw = np.hstack((val_raw_text, val_raw_ratings))\n",
    "\n",
    "test_df = pd.DataFrame(test_concat_raw,columns=[\"text\",\"labels\"])\n",
    "train_df = pd.DataFrame(train_concat_raw,columns=[\"text\",\"labels\"])\n",
    "val_df = pd.DataFrame(val_concat_raw,columns=[\"text\",\"labels\"])\n",
    "\n",
    "train_dict = train_df.to_dict(orient=\"list\")\n",
    "test_dict = test_df.to_dict(orient=\"list\")\n",
    "validation_dict = val_df.to_dict(orient=\"list\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 8000/8000 [00:01<00:00, 7018.74 examples/s]\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 6520.04 examples/s]\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 6853.90 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labels', 'input_ids', 'attention_mask']\n",
      "Batch input_ids shape: torch.Size([8, 512])\n",
      "Batch attention_mask shape: torch.Size([8, 512])\n",
      "Batch labels shape: torch.Size([8])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 30:59, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.552700</td>\n",
       "      <td>0.452690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.441100</td>\n",
       "      <td>0.503328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.349900</td>\n",
       "      <td>0.548935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.271800</td>\n",
       "      <td>0.625534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.659299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5000, training_loss=0.3721426010131836, metrics={'train_runtime': 1860.1805, 'train_samples_per_second': 21.503, 'train_steps_per_second': 2.688, 'total_flos': 1.052453670912e+16, 'train_loss': 0.3721426010131836, 'epoch': 5.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification,  TrainingArguments, Trainer\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_dict)\n",
    "test_dataset = Dataset.from_dict(test_dict)\n",
    "validation_dataset = Dataset.from_dict(validation_dict)\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels = 3)\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding=\"max_length\")\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "validation_dataset = validation_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.remove_columns([ \"text\", \"token_type_ids\"])\n",
    "test_dataset = test_dataset.remove_columns([ \"text\", \"token_type_ids\"])\n",
    "validation_dataset = validation_dataset.remove_columns([ \"text\", \"token_type_ids\"])\n",
    "\n",
    "print(train_dataset.column_names)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=1e-5,\n",
    "    use_cpu=False,\n",
    "    seed = 50)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "\n",
    "\n",
    ")\n",
    "for batch in trainer.get_train_dataloader():\n",
    "    print(f\"Batch input_ids shape: {batch['input_ids'].shape}\")\n",
    "    print(f\"Batch attention_mask shape: {batch['attention_mask'].shape}\")\n",
    "    print(f\"Batch labels shape: {batch['labels'].shape}\")\n",
    "    break\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(\"./trained_model\")\n",
    "trainer.save_model(\"./trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80       232\n",
      "           1       0.33      0.35      0.34        89\n",
      "           2       0.91      0.94      0.92       679\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.70      0.68      0.69      1000\n",
      "weighted avg       0.84      0.84      0.84      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = trainer.predict(validation_dataset)\n",
    "logits = predictions.predictions\n",
    "labels = predictions.label_ids\n",
    "predicted_classes = np.argmax(logits, axis=-1)\n",
    "\n",
    "\n",
    "print(classification_report(labels,predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.68      0.71       233\n",
      "           1       0.17      0.21      0.19        86\n",
      "           2       0.89      0.90      0.90       681\n",
      "\n",
      "    accuracy                           0.79      1000\n",
      "   macro avg       0.61      0.60      0.60      1000\n",
      "weighted avg       0.80      0.79      0.79      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predictions = trainer.predict(test_dataset)\n",
    "logits = predictions.predictions\n",
    "labels = predictions.label_ids\n",
    "predicted_classes = np.argmax(logits, axis=-1)\n",
    "\n",
    "\n",
    "print(classification_report(labels,predicted_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
